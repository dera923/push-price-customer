"""
KARTEãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«åŸºã¥ããƒªã‚¢ãƒ«ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨
Googleãƒ»Metaãƒ»NASAç´šã®å‡¦ç½®åŠ¹æœæ¨å®šã®ãŸã‚ã®ç²¾å¯†ã‚µãƒ³ãƒ—ãƒ«

å®Ÿè£…è€…ï¼šãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆå‘ã‘å³æˆ¦åŠ›ã‚³ãƒ¼ãƒ‰
å‚è€ƒï¼šImbens&Rubin "Causal Inference" Ch19, Murphy Ch21
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import hashlib
import uuid
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class KARTEDataGenerator:
    """
    KARTEã®å®Ÿéš›ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«åŸºã¥ãã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    
    ç‰¹å¾´ï¼š
    1. ç¾å®Ÿçš„ãªé¡§å®¢è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å†ç¾
    2. å‡¦ç½®åŠ¹æœã®ç•°è³ªæ€§ï¼ˆheterogeneous treatment effectï¼‰ã‚’çµ„ã¿è¾¼ã¿
    3. Selection biasã¨Confoundingã‚’æ„å›³çš„ã«ä½œæˆ
    4. Google/Metaç´šã®è©•ä¾¡æŒ‡æ¨™ã«å¯¾å¿œ
    """
    
    def __init__(self, n_customers=10000, n_days=90, seed=42):
        np.random.seed(seed)
        self.n_customers = n_customers
        self.n_days = n_days
        self.start_date = datetime(2024, 7, 1)
        self.end_date = self.start_date + timedelta(days=n_days-1)
        
        # ç¾å®Ÿçš„ãªé¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å¸ƒï¼ˆãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å®Ÿå‹™ã«åŸºã¥ãï¼‰
        self.customer_segments = {
            'high_value': 0.15,    # é«˜ä¾¡å€¤é¡§å®¢ï¼š15%
            'regular': 0.60,       # ä¸€èˆ¬é¡§å®¢ï¼š60%
            'dormant': 0.20,       # ä¼‘çœ é¡§å®¢ï¼š20%
            'new': 0.05           # æ–°è¦é¡§å®¢ï¼š5%
        }
    
    def generate_customer_master(self):
        """
        majica_member_informationç›¸å½“ã®ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
        
        é‡è¦ï¼šSelection biasã‚’æ„å›³çš„ã«ä½œæˆ
        - é«˜ä¾¡å€¤é¡§å®¢ã»ã©Pushé…ä¿¡ã•ã‚Œã‚„ã™ã„
        - ã—ã‹ã—å…ƒã€…è³¼è²·ç‡ãŒé«˜ã„ãŸã‚è¦‹ã‹ã‘ã®UpliftåŠ¹æœã¯ä½ãè¦‹ãˆã‚‹
        """
        customers = []
        
        for i in range(self.n_customers):
            # é¡§å®¢IDã¨hash_idï¼ˆKARTEã®å®Ÿæ§‹é€ ï¼‰
            majica_no = f"MJ{i:08d}"
            hash_id = hashlib.md5(majica_no.encode()).hexdigest()[:16]
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ±ºå®šï¼ˆç¾å®Ÿçš„ãªåˆ†å¸ƒï¼‰
            segment_prob = np.random.random()
            if segment_prob < 0.15:
                segment = 'high_value'
                rfm_score = np.random.normal(85, 10)
                loyalty_tier = np.random.choice(['PLATINUM', 'GOLD'], p=[0.7, 0.3])
                age_band = np.random.choice(['30-39', '40-49', '50-59'], p=[0.3, 0.4, 0.3])
            elif segment_prob < 0.75:
                segment = 'regular'
                rfm_score = np.random.normal(60, 15)
                loyalty_tier = np.random.choice(['SILVER', 'BRONZE'], p=[0.6, 0.4])
                age_band = np.random.choice(['20-29', '30-39', '40-49'], p=[0.3, 0.4, 0.3])
            elif segment_prob < 0.95:
                segment = 'dormant'
                rfm_score = np.random.normal(25, 10)
                loyalty_tier = 'BRONZE'
                age_band = np.random.choice(['20-29', '50-59', '60+'], p=[0.2, 0.4, 0.4])
            else:
                segment = 'new'
                rfm_score = np.random.normal(40, 5)
                loyalty_tier = 'BRONZE'
                age_band = np.random.choice(['20-29', '30-39'], p=[0.6, 0.4])
            
            # ã‚¯ãƒªãƒƒãƒ—ã—ã¦ç¾å®Ÿçš„ãªç¯„å›²ã«
            rfm_score = np.clip(rfm_score, 0, 100)
            
            customers.append({
                'hash_id': hash_id,
                'majica_no': majica_no,
                'segment': segment,
                'member_class': loyalty_tier,
                'rfm_score': round(rfm_score, 1),
                'bounce_class_cdm': np.random.choice(['LOW', 'MEDIUM', 'HIGH'], p=[0.6, 0.3, 0.1]),
                'contact_member_class': np.random.choice(['CONTACTABLE', 'LIMITED', 'NO_CONTACT'], p=[0.7, 0.2, 0.1]),
                'mobile_owned_class': np.random.choice(['OWNED', 'NOT_OWNED'], p=[0.85, 0.15]),
                'thankyou_mail_received': np.random.choice(['YES', 'NO'], p=[0.6, 0.4]),
                'newsletter_received': np.random.choice(['YES', 'NO'], p=[0.4, 0.6]),
                'coupon_availability_class': np.random.choice(['AVAILABLE', 'LIMITED'], p=[0.8, 0.2]),
                'age_band': age_band,
                'integrated_datetime': self.start_date - timedelta(days=np.random.randint(30, 1000))
            })
        
        df_customers = pd.DataFrame(customers)
        print(f"âœ“ é¡§å®¢ãƒã‚¹ã‚¿ç”Ÿæˆå®Œäº†: {len(df_customers):,}ä»¶")
        print(f"  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å¸ƒ: {df_customers['segment'].value_counts().to_dict()}")
        
        return df_customers
    
    def generate_push_logs(self, df_customers):
        """
        masspush_event_log_regionalç›¸å½“ã®ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
        
        é‡è¦ï¼šTreatment assignment mechanism
        - RFMã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©é…ä¿¡ã•ã‚Œã‚„ã™ã„ï¼ˆSelection biasï¼‰
        - ã—ã‹ã—å®Œå…¨ã«æ±ºå®šè«–çš„ã§ã¯ãªã„ï¼ˆRandomnessä¿æŒï¼‰
        """
        push_logs = []
        
        # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³è¨­å®šï¼ˆç¾å®Ÿçš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        campaigns = [
            {'campaign_id': 'SUMMER_SALE_001', 'start_day': 10, 'duration': 7, 'target_prob': 0.3},
            {'campaign_id': 'FLASH_SALE_002', 'start_day': 25, 'duration': 3, 'target_prob': 0.5},
            {'campaign_id': 'WEEKLY_RECOMMEND_003', 'start_day': 35, 'duration': 14, 'target_prob': 0.2},
            {'campaign_id': 'REACTIVATION_004', 'start_day': 55, 'duration': 10, 'target_prob': 0.4}
        ]
        
        for _, customer in df_customers.iterrows():
            for campaign in campaigns:
                campaign_start = self.start_date + timedelta(days=campaign['start_day'])
                
                # Selection bias: RFMã‚¹ã‚³ã‚¢ã«åŸºã¥ãé…ä¿¡ç¢ºç‡
                # é«˜RFM â†’ é«˜é…ä¿¡ç¢ºç‡ã ãŒã€å…ƒã€…è³¼è²·ç‡ã‚‚é«˜ã„
                rfm_factor = (customer['rfm_score'] / 100) ** 0.5
                base_prob = campaign['target_prob']
                treatment_prob = base_prob * (0.5 + 0.5 * rfm_factor)
                treatment_prob = np.clip(treatment_prob, 0.05, 0.95)
                
                # å‡¦ç½®å‰²å½“ï¼ˆäºŒå€¤ï¼‰
                is_treated = np.random.random() < treatment_prob
                
                if is_treated:
                    for day_offset in range(campaign['duration']):
                        send_date = campaign_start + timedelta(days=day_offset)
                        if send_date <= self.end_date:
                            
                            # é€ä¿¡ãƒ­ã‚°
                            event_hash = hashlib.md5(f"{customer['hash_id']}{send_date}{campaign['campaign_id']}send".encode()).hexdigest()[:12]
                            push_logs.append({
                                'event_hash': event_hash,
                                'event_name': 'message_send',
                                'api_key': 'karte_api_demo',
                                'user_data_list': customer['hash_id'],
                                'timestamp': send_date + timedelta(hours=np.random.randint(9, 18)),
                                'campaign_id': campaign['campaign_id'],
                                'push_content_id': f"CONTENT_{campaign['campaign_id']}",
                                'plugin_type': 'push_notification',
                                'schedule_id': f"SCH_{campaign['campaign_id']}",
                                'schedule_task_id': f"TASK_{day_offset}",
                                'error_type': None
                            })
                            
                            # ã‚¯ãƒªãƒƒã‚¯ç¢ºç‡ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¾å­˜ï¼‰
                            if customer['segment'] == 'high_value':
                                click_prob = 0.15
                            elif customer['segment'] == 'regular':
                                click_prob = 0.08
                            elif customer['segment'] == 'dormant':
                                click_prob = 0.03
                            else:  # new
                                click_prob = 0.12
                            
                            # ã‚¯ãƒªãƒƒã‚¯ãƒ­ã‚°ç”Ÿæˆ
                            if np.random.random() < click_prob:
                                click_hash = hashlib.md5(f"{customer['hash_id']}{send_date}{campaign['campaign_id']}click".encode()).hexdigest()[:12]
                                push_logs.append({
                                    'event_hash': click_hash,
                                    'event_name': 'message_click',
                                    'api_key': 'karte_api_demo',
                                    'user_data_list': customer['hash_id'],
                                    'timestamp': send_date + timedelta(hours=np.random.randint(9, 20), minutes=np.random.randint(0, 59)),
                                    'campaign_id': campaign['campaign_id'],
                                    'push_content_id': f"CONTENT_{campaign['campaign_id']}",
                                    'plugin_type': 'push_notification',
                                    'schedule_id': f"SCH_{campaign['campaign_id']}",
                                    'schedule_task_id': f"TASK_{day_offset}",
                                    'error_type': None
                                })
                
                # CONTROL_GROUPï¼ˆæœªé…ä¿¡ï¼‰è¨˜éŒ²
                else:
                    control_hash = hashlib.md5(f"{customer['hash_id']}{campaign_start}{campaign['campaign_id']}control".encode()).hexdigest()[:12]
                    push_logs.append({
                        'event_hash': control_hash,
                        'event_name': 'control_group',
                        'api_key': 'karte_api_demo',
                        'user_data_list': customer['hash_id'],
                        'timestamp': campaign_start,
                        'campaign_id': campaign['campaign_id'],
                        'push_content_id': 'CONTROL_GROUP',
                        'plugin_type': 'push_notification',
                        'schedule_id': f"SCH_{campaign['campaign_id']}",
                        'schedule_task_id': 'CONTROL',
                        'error_type': None
                    })
        
        df_push_logs = pd.DataFrame(push_logs)
        print(f"âœ“ Pushé…ä¿¡ãƒ­ã‚°ç”Ÿæˆå®Œäº†: {len(df_push_logs):,}ä»¶")
        print(f"  ã‚¤ãƒ™ãƒ³ãƒˆåˆ†å¸ƒ: {df_push_logs['event_name'].value_counts().to_dict()}")
        
        return df_push_logs
    
    def generate_purchase_data(self, df_customers, df_push_logs):
        """
        pos_trade_item_salesç›¸å½“ã®ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
        
        é‡è¦ï¼šHeterogeneous Treatment Effect
        - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ã«ç•°ãªã‚‹UpliftåŠ¹æœ
        - Pushé…ä¿¡ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°åŠ¹æœï¼ˆçŸ­æœŸãƒ»ä¸­æœŸï¼‰
        """
        purchases = []
        
        # å•†å“ã‚«ãƒ†ã‚´ãƒªï¼ˆç¾å®Ÿçš„ãªåˆ†å¸ƒï¼‰
        product_categories = {
            'FOOD': {'weight': 0.4, 'avg_price': 500, 'repeat_rate': 0.7},
            'COSMETICS': {'weight': 0.25, 'avg_price': 2000, 'repeat_rate': 0.3},
            'CLOTHING': {'weight': 0.2, 'avg_price': 3500, 'repeat_rate': 0.2},
            'ELECTRONICS': {'weight': 0.1, 'avg_price': 8000, 'repeat_rate': 0.1},
            'OTHER': {'weight': 0.05, 'avg_price': 1200, 'repeat_rate': 0.4}
        }
        
        # Pushé…ä¿¡å±¥æ­´ã‚’é¡§å®¢åˆ¥ã«æ•´ç†
        push_by_customer = df_push_logs.groupby('user_data_list').agg({
            'timestamp': list,
            'event_name': list,
            'campaign_id': list
        }).to_dict('index')
        
        for _, customer in df_customers.iterrows():
            hash_id = customer['hash_id']
            segment = customer['segment']
            rfm_score = customer['rfm_score']
            
            # ãƒ™ãƒ¼ã‚¹è³¼è²·ç¢ºç‡ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¾å­˜ï¼‰
            if segment == 'high_value':
                base_purchase_prob = 0.12  # 1æ—¥ã‚ãŸã‚Š12%
                avg_basket_size = 2.5
            elif segment == 'regular':
                base_purchase_prob = 0.05  # 1æ—¥ã‚ãŸã‚Š5%
                avg_basket_size = 1.8
            elif segment == 'dormant':
                base_purchase_prob = 0.01  # 1æ—¥ã‚ãŸã‚Š1%
                avg_basket_size = 1.2
            else:  # new
                base_purchase_prob = 0.03  # 1æ—¥ã‚ãŸã‚Š3%
                avg_basket_size = 1.5
            
            # æ—¥åˆ¥ã®è³¼è²·ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            for day_offset in range(self.n_days):
                current_date = self.start_date + timedelta(days=day_offset)
                
                # ãã®æ—¥ã®Pushé…ä¿¡çŠ¶æ³ãƒã‚§ãƒƒã‚¯
                push_effect = 0.0
                if hash_id in push_by_customer:
                    customer_pushes = push_by_customer[hash_id]
                    for i, push_timestamp in enumerate(customer_pushes['timestamp']):
                        if isinstance(push_timestamp, list):
                            push_timestamps = push_timestamp
                        else:
                            push_timestamps = [push_timestamp]
                        
                        for push_ts in push_timestamps:
                            if isinstance(push_ts, str):
                                push_ts = pd.to_datetime(push_ts)
                            
                            days_since_push = (current_date - push_ts.date()).days
                            
                            # PushåŠ¹æœï¼ˆæ™‚é–“æ¸›è¡°ï¼‰
                            if 0 <= days_since_push <= 7:
                                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ã®UpliftåŠ¹æœï¼ˆç•°è³ªæ€§ï¼‰
                                if segment == 'high_value':
                                    uplift_base = 0.03  # 3%ã®è¿½åŠ è³¼è²·ç¢ºç‡
                                elif segment == 'regular':
                                    uplift_base = 0.08  # 8%ã®è¿½åŠ è³¼è²·ç¢ºç‡ï¼ˆæœ€ã‚‚åŠ¹æœçš„ï¼‰
                                elif segment == 'dormant':
                                    uplift_base = 0.15  # 15%ã®è¿½åŠ è³¼è²·ç¢ºç‡ï¼ˆä¼‘çœ è¦šé†’ï¼‰
                                else:  # new
                                    uplift_base = 0.10  # 10%ã®è¿½åŠ è³¼è²·ç¢ºç‡
                                
                                # æ™‚é–“æ¸›è¡°
                                time_decay = np.exp(-days_since_push * 0.3)
                                push_effect += uplift_base * time_decay
                
                # æœ€çµ‚çš„ãªè³¼è²·ç¢ºç‡
                final_purchase_prob = base_purchase_prob + push_effect
                final_purchase_prob = np.clip(final_purchase_prob, 0, 0.8)
                
                # è³¼è²·åˆ¤å®š
                if np.random.random() < final_purchase_prob:
                    # ãƒã‚¹ã‚±ãƒƒãƒˆã‚µã‚¤ã‚ºæ±ºå®š
                    n_items = max(1, int(np.random.poisson(avg_basket_size)))
                    
                    for item_idx in range(n_items):
                        # å•†å“ã‚«ãƒ†ã‚´ãƒªé¸æŠ
                        category = np.random.choice(
                            list(product_categories.keys()),
                            p=[cat['weight'] for cat in product_categories.values()]
                        )
                        cat_info = product_categories[category]
                        
                        # å•†å“è©³ç´°
                        sku_id = f"SKU_{category}_{np.random.randint(1000, 9999)}"
                        
                        # ä¾¡æ ¼ï¼ˆæ­£è¦åˆ†å¸ƒ + ãƒ­ã‚°å¤‰æ›ã§ç¾å®Ÿçš„ãªåˆ†å¸ƒï¼‰
                        price_base = cat_info['avg_price']
                        price_variation = np.random.lognormal(0, 0.5)
                        sales_price = max(100, int(price_base * price_variation))
                        
                        # å‰²å¼•è¨­å®šï¼ˆPushåŠ¹æœã§å‰²å¼•ç‡å¤‰å‹•ï¼‰
                        discount_rate = 0.0
                        if push_effect > 0.05:  # å¼·ã„PushåŠ¹æœãŒã‚ã‚‹å ´åˆ
                            discount_rate = np.random.uniform(0.05, 0.2)
                        elif push_effect > 0.02:
                            discount_rate = np.random.uniform(0.0, 0.1)
                        
                        final_price = int(sales_price * (1 - discount_rate))
                        
                        purchases.append({
                            'majica_no': customer['majica_no'],
                            'hash_id': hash_id,
                            'date': current_date.date(),
                            'sku_id': sku_id,
                            'category': category,
                            'quantity': 1,
                            'list_price': sales_price,
                            'sales_price': final_price,
                            'discount_amount': sales_price - final_price,
                            'discount_rate': discount_rate,
                            'segment': segment,
                            'rfm_score': rfm_score,
                            'push_effect_score': round(push_effect, 4),
                            'taxfree_group_class': np.random.choice(['TAXFREE', 'TAXABLE'], p=[0.1, 0.9]),
                            'floor_no': np.random.choice(['B1', '1F', '2F', '3F'], p=[0.3, 0.4, 0.2, 0.1]),
                            'customer_quantity_daily': n_items
                        })
        
        df_purchases = pd.DataFrame(purchases)
        print(f"âœ“ è³¼è²·ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(df_purchases):,}ä»¶")
        print(f"  æ—¥å¹³å‡è³¼è²·ä»¶æ•°: {len(df_purchases)/self.n_days:.1f}ä»¶")
        print(f"  ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ: {df_purchases['category'].value_counts().to_dict()}")
        
        return df_purchases
    
    def create_analysis_dataset(self, df_customers, df_push_logs, df_purchases):
        """
        Upliftãƒ¢ãƒ‡ãƒªãƒ³ã‚°ç”¨ã®çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        
        é‡è¦ï¼šã“ã®çµ±åˆãƒ—ãƒ­ã‚»ã‚¹ãŒGoogleãƒ»Metaãƒ»NASAã§æœ€ã‚‚é‡è¦
        - é¡§å®¢Ã—æ—¥ä»˜ãƒ¬ãƒ™ãƒ«ã§ã®è¦³æ¸¬å˜ä½çµ±ä¸€
        - Treatment assignment flagã®æ­£ç¢ºãªä½œæˆ
        - Confounding variablesã®é©åˆ‡ãªè¨­è¨ˆ
        """
        analysis_data = []
        
        # Pushé…ä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥åˆ¥ãƒ»é¡§å®¢åˆ¥ã«é›†ç´„
        push_summary = df_push_logs.groupby(['user_data_list', pd.to_datetime(df_push_logs['timestamp']).dt.date]).agg({
            'event_name': lambda x: 'message_send' in list(x),
            'campaign_id': 'first'
        }).reset_index()
        push_summary.columns = ['hash_id', 'date', 'push_sent', 'campaign_id']
        
        # è³¼è²·ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥åˆ¥ãƒ»é¡§å®¢åˆ¥ã«é›†ç´„
        purchase_summary = df_purchases.groupby(['hash_id', 'date']).agg({
            'quantity': 'sum',
            'sales_price': 'sum',
            'discount_amount': 'sum',
            'push_effect_score': 'mean',
            'category': lambda x: ','.join(list(set(x)))
        }).reset_index()
        
        # é¡§å®¢Ã—æ—¥ä»˜ã®å…¨çµ„ã¿åˆã‚ã›ä½œæˆ
        all_customers = df_customers['hash_id'].unique()
        all_dates = pd.date_range(self.start_date.date(), self.end_date.date(), freq='D')
        
        for customer_id in all_customers:
            customer_info = df_customers[df_customers['hash_id'] == customer_id].iloc[0]
            
            for date in all_dates:
                # Pushå‡¦ç½®ãƒ•ãƒ©ã‚°
                push_info = push_summary[(push_summary['hash_id'] == customer_id) & 
                                       (push_summary['date'] == date)]
                treatment = 1 if len(push_info) > 0 and push_info.iloc[0]['push_sent'] else 0
                
                # è³¼è²·ã‚¢ã‚¦ãƒˆã‚«ãƒ 
                purchase_info = purchase_summary[(purchase_summary['hash_id'] == customer_id) & 
                                               (purchase_summary['date'] == date)]
                
                if len(purchase_info) > 0:
                    purchase_flag = 1
                    total_spend = purchase_info.iloc[0]['sales_price']
                    total_quantity = purchase_info.iloc[0]['quantity']
                    push_effect = purchase_info.iloc[0]['push_effect_score']
                else:
                    purchase_flag = 0
                    total_spend = 0
                    total_quantity = 0
                    push_effect = 0
                
                # æ™‚é–“çš„ç‰¹å¾´é‡
                day_of_week = date.weekday()
                is_weekend = 1 if day_of_week >= 5 else 0
                days_since_start = (date - self.start_date.date()).days
                
                # éå»ã®è³¼è²·å±¥æ­´ï¼ˆãƒ©ã‚°ç‰¹å¾´é‡ï¼‰
                past_purchases = df_purchases[
                    (df_purchases['hash_id'] == customer_id) & 
                    (df_purchases['date'] < date) &
                    (df_purchases['date'] >= date - timedelta(days=30))
                ]
                past_30d_purchases = len(past_purchases)
                past_30d_spend = past_purchases['sales_price'].sum() if len(past_purchases) > 0 else 0
                
                analysis_data.append({
                    'hash_id': customer_id,
                    'date': date,
                    'treatment': treatment,  # Pushé…ä¿¡ãƒ•ãƒ©ã‚°ï¼ˆäºŒå€¤å‡¦ç½®ï¼‰
                    'outcome_purchase': purchase_flag,  # è³¼è²·ãƒ•ãƒ©ã‚°ï¼ˆä¸»è¦ã‚¢ã‚¦ãƒˆã‚«ãƒ ï¼‰
                    'outcome_spend': total_spend,  # è³¼è²·é‡‘é¡
                    'outcome_quantity': total_quantity,  # è³¼è²·ç‚¹æ•°
                    'true_push_effect': push_effect,  # çœŸã®PushåŠ¹æœï¼ˆè©•ä¾¡ç”¨ï¼‰
                    
                    # é¡§å®¢å±æ€§ï¼ˆConfoundersï¼‰
                    'segment': customer_info['segment'],
                    'rfm_score': customer_info['rfm_score'],
                    'loyalty_tier': customer_info['member_class'],
                    'age_band': customer_info['age_band'],
                    'mobile_owned': 1 if customer_info['mobile_owned_class'] == 'OWNED' else 0,
                    
                    # æ™‚é–“ç‰¹å¾´é‡
                    'day_of_week': day_of_week,
                    'is_weekend': is_weekend,
                    'days_since_start': days_since_start,
                    
                    # ãƒ©ã‚°ç‰¹å¾´é‡ï¼ˆSelection biasã‚’ä½œã‚‹é‡è¦ãªå¤‰æ•°ï¼‰
                    'past_30d_purchases': past_30d_purchases,
                    'past_30d_spend': past_30d_spend,
                    'has_recent_purchase': 1 if past_30d_purchases > 0 else 0
                })
        
        df_analysis = pd.DataFrame(analysis_data)
        
        # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        df_analysis = pd.get_dummies(df_analysis, columns=['segment', 'loyalty_tier', 'age_band'], 
                                   prefix=['seg', 'tier', 'age'], drop_first=True)
        
        print(f"âœ“ åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {len(df_analysis):,}ä»¶")
        print(f"  å‡¦ç½®ç¾¤æ¯”ç‡: {df_analysis['treatment'].mean():.3f}")
        print(f"  è³¼è²·ç‡ï¼ˆå‡¦ç½®ç¾¤ï¼‰: {df_analysis[df_analysis['treatment']==1]['outcome_purchase'].mean():.3f}")
        print(f"  è³¼è²·ç‡ï¼ˆå¯¾ç…§ç¾¤ï¼‰: {df_analysis[df_analysis['treatment']==0]['outcome_purchase'].mean():.3f}")
        print(f"  ç´ æœ´ãªåŠ¹æœå·®: {df_analysis[df_analysis['treatment']==1]['outcome_purchase'].mean() - df_analysis[df_analysis['treatment']==0]['outcome_purchase'].mean():.4f}")
        
        return df_analysis

def main():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ KARTEãƒªã‚¢ãƒ«ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹")
    print("=" * 60)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    Path("customer_axis/2_2_uplift_modeling/sample_data").mkdir(parents=True, exist_ok=True)
    
    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨åˆæœŸåŒ–
    generator = KARTEDataGenerator(n_customers=5000, n_days=60, seed=42)
    
    # å„ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ
    print("\nğŸ“Š 1. é¡§å®¢ãƒã‚¹ã‚¿ç”Ÿæˆ")
    df_customers = generator.generate_customer_master()
    
    print("\nğŸ“± 2. Pushé…ä¿¡ãƒ­ã‚°ç”Ÿæˆ")
    df_push_logs = generator.generate_push_logs(df_customers)
    
    print("\nğŸ’° 3. è³¼è²·ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ")
    df_purchases = generator.generate_purchase_data(df_customers, df_push_logs)
    
    print("\nğŸ”— 4. åˆ†æç”¨çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ")
    df_analysis = generator.create_analysis_dataset(df_customers, df_push_logs, df_purchases)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    output_dir = Path("customer_axis/2_2_uplift_modeling/sample_data")
    
    df_customers.to_csv(output_dir / "karte_customers.csv", index=False)
    df_push_logs.to_csv(output_dir / "karte_push_logs.csv", index=False)
    df_purchases.to_csv(output_dir / "karte_purchases.csv", index=False)
    df_analysis.to_csv(output_dir / "uplift_analysis_dataset.csv", index=False)
    
    print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†ï¼ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å…ˆ: {output_dir}")
    print("\nğŸ“‹ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"  - karte_customers.csv ({len(df_customers):,} records)")
    print(f"  - karte_push_logs.csv ({len(df_push_logs):,} records)")  
    print(f"  - karte_purchases.csv ({len(df_purchases):,} records)")
    print(f"  - uplift_analysis_dataset.csv ({len(df_analysis):,} records)")
    
    return df_analysis

if __name__ == "__main__":
    df_uplift = main()
