# apps/generate_sample_data.py

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import os

def generate_sample_push_data(n_samples=10000, seed=42):
    """
    Pushé…ä¿¡åŠ¹æœåˆ†æç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    Googleã®A/Bãƒ†ã‚¹ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’å‚è€ƒã«å®Ÿè£…
    ç¾å®Ÿçš„ãªåŠ¹æœã‚µã‚¤ã‚ºã¨ãƒã‚¤ã‚ºã‚’å«ã‚€
    """
    np.random.seed(seed)
    
    print("="*60)
    print("ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ")
    print("="*60)
    
    # 1. é¡§å®¢ç‰¹å¾´é‡ã®ç”Ÿæˆ
    print("\n1ï¸âƒ£ é¡§å®¢ç‰¹å¾´é‡ã‚’ç”Ÿæˆä¸­...")
    
    # å¹´é½¢ï¼ˆæ­£è¦åˆ†å¸ƒã€20-70æ­³ï¼‰
    age = np.clip(np.random.normal(40, 15, n_samples), 20, 70).astype(int)
    
    # æ€§åˆ¥ï¼ˆ0: å¥³æ€§, 1: ç”·æ€§ï¼‰
    gender_male = np.random.binomial(1, 0.45, n_samples)
    
    # RFMç‰¹å¾´é‡
    # Recency: æœ€çµ‚è³¼è²·ã‹ã‚‰ã®æ—¥æ•°ï¼ˆæŒ‡æ•°åˆ†å¸ƒï¼‰
    recency_days = np.clip(np.random.exponential(10, n_samples), 1, 365).astype(int)
    
    # Frequency: 30æ—¥é–“ã®è³¼è²·å›æ•°ï¼ˆãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒï¼‰
    frequency_30d = np.random.poisson(5, n_samples)
    
    # Monetary: 30æ—¥é–“ã®è³¼è²·é‡‘é¡ï¼ˆå¯¾æ•°æ­£è¦åˆ†å¸ƒï¼‰
    monetary_30d = np.exp(np.random.normal(8, 1.5, n_samples))
    
    # éå»ã®è³¼è²·å±¥æ­´ï¼ˆCUPEDç”¨ï¼‰
    prev_week_sales = np.exp(np.random.normal(7, 1.5, n_samples))
    prev_month_sales = np.exp(np.random.normal(8.5, 1.5, n_samples))
    
    # 2. å‚¾å‘ã‚¹ã‚³ã‚¢ã®çœŸå€¤ã‚’è¨ˆç®—ï¼ˆè¦³æ¸¬ã•ã‚Œãªã„ï¼‰
    print("2ï¸âƒ£ å‡¦ç½®å‰²ã‚Šå½“ã¦ã‚’ç”Ÿæˆä¸­...")
    
    # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«ã§å‚¾å‘ã‚¹ã‚³ã‚¢ã‚’æ±ºå®š
    # è‹¥ã„äººã€é »ç¹ã«è²·ã†äººã»ã©Pushé…ä¿¡ã•ã‚Œã‚‹ç¢ºç‡ãŒé«˜ã„
    logit_ps = (
        -2.0 +  # åˆ‡ç‰‡
        -0.02 * (age - 40) +  # å¹´é½¢åŠ¹æœ
        0.1 * frequency_30d +  # é »åº¦åŠ¹æœ
        0.3 * (monetary_30d > np.median(monetary_30d)) +  # é«˜é¡è³¼å…¥è€…
        0.2 * gender_male  # æ€§åˆ¥åŠ¹æœ
    )
    
    # çœŸã®å‚¾å‘ã‚¹ã‚³ã‚¢
    true_propensity = 1 / (1 + np.exp(-logit_ps))
    
    # å‡¦ç½®å‰²ã‚Šå½“ã¦ï¼ˆPushé…ä¿¡æœ‰ç„¡ï¼‰
    treated = np.random.binomial(1, true_propensity)
    
    print(f"   å‡¦ç½®ç¾¤: {treated.sum():,} ({treated.mean()*100:.1f}%)")
    print(f"   çµ±åˆ¶ç¾¤: {(1-treated).sum():,} ({(1-treated).mean()*100:.1f}%)")
    
    # 3. æ½œåœ¨çµæœã®ç”Ÿæˆ
    print("3ï¸âƒ£ è³¼è²·çµæœã‚’ç”Ÿæˆä¸­...")
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®è³¼è²·é¡ï¼ˆå‡¦ç½®ãªã—ã®å ´åˆï¼‰
    baseline_sales = (
        1000 +  # åŸºæœ¬è³¼è²·é¡
        50 * frequency_30d +  # é »åº¦ã«ã‚ˆã‚‹å¢—åŠ 
        0.1 * monetary_30d +  # éå»ã®è³¼è²·é¡ã®å½±éŸ¿
        -10 * (age - 40) +  # å¹´é½¢åŠ¹æœ
        500 * gender_male +  # æ€§åˆ¥åŠ¹æœ
        0.3 * prev_week_sales +  # è‡ªå·±ç›¸é–¢
        np.random.normal(0, 500, n_samples)  # ãƒã‚¤ã‚º
    )
    
    # å‡¦ç½®åŠ¹æœï¼ˆç•°è³ªåŠ¹æœã‚’å«ã‚€ï¼‰
    # è‹¥ã„äººã€é »ç¹ã«è²·ã†äººã»ã©åŠ¹æœãŒå¤§ãã„
    individual_treatment_effect = (
        500 +  # å¹³å‡å‡¦ç½®åŠ¹æœ
        -5 * (age - 40) +  # å¹´é½¢ã«ã‚ˆã‚‹åŠ¹æœã®é•ã„
        20 * frequency_30d +  # é »åº¦ã«ã‚ˆã‚‹åŠ¹æœã®é•ã„
        np.random.normal(0, 200, n_samples)  # å€‹äººå·®
    )
    
    # è¦³æ¸¬ã•ã‚Œã‚‹è³¼è²·é¡
    outcome_sales = baseline_sales + treated * individual_treatment_effect
    outcome_sales = np.maximum(0, outcome_sales)  # è² ã®å€¤ã‚’0ã«
    
    # è³¼è²·å€‹æ•°ï¼ˆè³¼è²·é¡ã¨ç›¸é–¢ï¼‰
    outcome_quantity = np.maximum(
        0,
        np.round(outcome_sales / 1000 + np.random.normal(0, 1, n_samples))
    ).astype(int)
    
    # 4. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
    print("4ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ§‹ç¯‰ä¸­...")
    
    df = pd.DataFrame({
        'customer_id': range(1, n_samples + 1),
        'treated': treated,
        'outcome_sales': outcome_sales,
        'outcome_quantity': outcome_quantity,
        'age': age,
        'gender_male': gender_male,
        'recency_days': recency_days,
        'frequency_30d': frequency_30d,
        'monetary_30d': monetary_30d,
        'prev_week_sales': prev_week_sales,
        'prev_month_sales': prev_month_sales,
        # è¨ºæ–­ç”¨ï¼ˆå®Ÿéš›ã®åˆ†æã§ã¯ä½¿ã‚ãªã„ï¼‰
        '_true_propensity': true_propensity,
        '_true_effect': individual_treatment_effect
    })
    
    # 5. ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„çµ±è¨ˆ
    print("\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿è¦ç´„çµ±è¨ˆ:")
    print("-"*40)
    
    # å‡¦ç½®ç¾¤ã¨çµ±åˆ¶ç¾¤ã®å¹³å‡ã‚’æ¯”è¼ƒ
    treated_mean = df[df['treated']==1]['outcome_sales'].mean()
    control_mean = df[df['treated']==0]['outcome_sales'].mean()
    naive_ate = treated_mean - control_mean
    
    print(f"å‡¦ç½®ç¾¤ã®å¹³å‡è³¼è²·é¡: {treated_mean:,.2f} å††")
    print(f"çµ±åˆ¶ç¾¤ã®å¹³å‡è³¼è²·é¡: {control_mean:,.2f} å††")
    print(f"å˜ç´”ãªå·®ï¼ˆãƒã‚¤ã‚¢ã‚¹ã‚ã‚Šï¼‰: {naive_ate:,.2f} å††")
    
    # çœŸã®å¹³å‡å‡¦ç½®åŠ¹æœï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãªã®ã§åˆ†ã‹ã‚‹ï¼‰
    true_ate = df['_true_effect'].mean()
    print(f"çœŸã®å¹³å‡å‡¦ç½®åŠ¹æœ: {true_ate:,.2f} å††")
    print(f"é¸æŠãƒã‚¤ã‚¢ã‚¹: {naive_ate - true_ate:,.2f} å††")
    
    return df

def save_sample_data(df, output_dir='data'):
    """
    ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    """
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆçœŸå€¤ã‚’é™¤å¤–ï¼‰
    analysis_cols = [col for col in df.columns if not col.startswith('_')]
    df_analysis = df[analysis_cols]
    
    # CSVå½¢å¼ã§ä¿å­˜ï¼ˆç¢ºèªç”¨ï¼‰
    csv_path = os.path.join(output_dir, 'sample_data.csv')
    df_analysis.to_csv(csv_path, index=False)
    print(f"\nğŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {csv_path}")
    
    # Parquetå½¢å¼ã§ä¿å­˜ï¼ˆåˆ†æç”¨ï¼‰
    parquet_path = os.path.join(output_dir, 'sample_data.parquet')
    df_analysis.to_parquet(parquet_path, index=False)
    print(f"ğŸ’¾ Parquetãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {parquet_path}")
    
    # çœŸå€¤ã‚’å«ã‚€å®Œå…¨ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¤œè¨¼ç”¨ï¼‰
    full_parquet_path = os.path.join(output_dir, 'sample_data_with_truth.parquet')
    df.to_parquet(full_parquet_path, index=False)
    print(f"ğŸ’¾ æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {full_parquet_path}")
    
    return csv_path, parquet_path

if __name__ == "__main__":
    # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
    print("\n" + "="*60)
    print("ğŸš€ Pushé…ä¿¡åŠ¹æœåˆ†æç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ")
    print("   Google/Metaæ°´æº–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*60)
    
    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df = generate_sample_push_data(n_samples=10000)
    
    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    csv_path, parquet_path = save_sample_data(df)
    
    print("\nâœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†ï¼")
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. ãƒ‡ãƒ¼ã‚¿ç¢ºèª: head data/sample_data.csv")
    print("2. åˆ†æå®Ÿè¡Œ: python apps/run_ate_analysis.py")
