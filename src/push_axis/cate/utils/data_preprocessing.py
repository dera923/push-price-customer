"""
CATEåˆ†æç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨
ãƒãƒ«ã‚¤ã®ãƒ—ãƒƒã‚·ãƒ¥é…ä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’æ¨¡ã—ãŸãƒªã‚¢ãƒ«ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

å‚è€ƒæ–‡çŒ®ï¼š
- KÃ¼nzel et al. (2019) "Metalearners for estimating heterogeneous treatment effects"
- Nie & Wager (2021) "Quasi-oracle estimation of heterogeneous treatment effects"
- Google Research: "Machine Learning for Treatment Effect Estimation"
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class CATESampleDataGenerator:
    """
    Google/Meta/NASAãƒ¬ãƒ™ãƒ«ã®é«˜å“è³ªCATEåˆ†æç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨
    
    ç‰¹å¾´ï¼š
    - ç¾å®Ÿçš„ãªé¡§å®¢ç‰¹å¾´é‡åˆ†å¸ƒ
    - è¤‡é›‘ãªç•°è³ªå‡¦ç½®åŠ¹æœãƒ‘ã‚¿ãƒ¼ãƒ³
    - äº¤çµ¡ãƒã‚¤ã‚¢ã‚¹ã®å†ç¾
    - å…±é€šã‚µãƒãƒ¼ãƒˆã®ä¿è¨¼
    """
    
    def __init__(self, n_samples=10000, random_state=42):
        self.n_samples = n_samples
        self.random_state = random_state
        np.random.seed(random_state)
        
    def generate_customer_features(self):
        """
        ãƒãƒ«ã‚¤é¡§å®¢ã‚’æ¨¡ã—ãŸç‰¹å¾´é‡ç”Ÿæˆ
        """
        # å¹´é½¢ï¼ˆ20-70æ­³ã€æ­£è¦åˆ†å¸ƒï¼‰
        age = np.clip(np.random.normal(40, 12, self.n_samples), 20, 70)
        
        # æ€§åˆ¥ï¼ˆã‚„ã‚„å¥³æ€§å¤šã‚ï¼šå®Ÿéš›ã®ãƒãƒ«ã‚¤é¡§å®¢åˆ†å¸ƒã‚’åæ˜ ï¼‰
        gender = np.random.choice([0, 1], self.n_samples, p=[0.4, 0.6])  # 0:ç”·æ€§, 1:å¥³æ€§
        
        # éå»ã®è³¼è²·å›æ•°ï¼ˆãƒ­ã‚°æ­£è¦åˆ†å¸ƒï¼šå°‘æ•°ã®ãƒ˜ãƒ“ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨å¤šæ•°ã®ãƒ©ã‚¤ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰
        purchase_count = np.random.lognormal(2, 1, self.n_samples)
        
        # å¹³å‡è³¼è²·å˜ä¾¡ï¼ˆå¹´é½¢ãƒ»æ€§åˆ¥ã¨ç›¸é–¢ï¼‰
        avg_purchase_amount = (
            5000 + 
            100 * age + 
            2000 * gender + 
            np.random.normal(0, 1000, self.n_samples)
        )
        avg_purchase_amount = np.clip(avg_purchase_amount, 1000, 50000)
        
        # ã‚¢ãƒ—ãƒªåˆ©ç”¨é »åº¦ï¼ˆè‹¥ã„ä¸–ä»£ã»ã©é«˜ã„ï¼‰
        app_usage = np.exp(-0.05 * (age - 20)) + np.random.exponential(0.5, self.n_samples)
        
        # åœ°åŸŸï¼ˆé–¢æ±åœä¸­å¿ƒï¼‰
        region = np.random.choice([0, 1, 2, 3], self.n_samples, p=[0.5, 0.2, 0.2, 0.1])
        # 0:é–¢æ±, 1:é–¢è¥¿, 2:ä¸­éƒ¨, 3:ãã®ä»–
        
        return pd.DataFrame({
            'age': age,
            'gender': gender,
            'purchase_count': purchase_count,
            'avg_purchase_amount': avg_purchase_amount,
            'app_usage': app_usage,
            'region': region
        })
    
    def true_cate_function(self, df):
        """
        çœŸã®æ¡ä»¶ä»˜ãå¹³å‡å‡¦ç½®åŠ¹æœï¼ˆCATEï¼‰é–¢æ•°
        
        Google/Metaã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å‚è€ƒã«ã—ãŸè¤‡é›‘ãªç•°è³ªåŠ¹æœãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š
        - å¹´é½¢ã«ã‚ˆã‚‹éç·šå½¢åŠ¹æœ
        - æ€§åˆ¥ã«ã‚ˆã‚‹äº¤äº’ä½œç”¨åŠ¹æœ
        - è³¼è²·è¡Œå‹•ã«ã‚ˆã‚‹ä¿®é£¾åŠ¹æœ
        """
        age = df['age'].values
        gender = df['gender'].values
        purchase_count = df['purchase_count'].values
        avg_purchase_amount = df['avg_purchase_amount'].values
        app_usage = df['app_usage'].values
        
        # åŸºæº–åŠ¹æœï¼ˆå…¨ä½“ã®å¹³å‡åŠ¹æœï¼‰
        base_effect = 0.08  # 8%ã®å£²ä¸Šå‘ä¸Š
        
        # å¹´é½¢åŠ¹æœï¼ˆUå­—ã‚«ãƒ¼ãƒ–ï¼š20ä»£ã¨50ä»£ã§é«˜åŠ¹æœï¼‰
        age_centered = (age - 40) / 10
        age_effect = 0.15 * np.exp(-0.5 * age_centered**2) - 0.05
        
        # æ€§åˆ¥åŠ¹æœï¼ˆå¥³æ€§ã«ã‚ˆã‚ŠåŠ¹æœçš„ï¼‰
        gender_effect = 0.12 * gender
        
        # è³¼è²·é »åº¦åŠ¹æœï¼ˆãƒ­ã‚°å¤‰æ›ã§é™ç•ŒåŠ¹ç”¨é€“æ¸›ï¼‰
        freq_effect = 0.1 * np.log(1 + purchase_count) - 0.02 * purchase_count**0.5
        
        # å˜ä¾¡åŠ¹æœï¼ˆé«˜å˜ä¾¡é¡§å®¢ã¯åŠ¹æœä½ã„ï¼šæ—¢ã«æº€è¶³åº¦é«˜ã„ãŸã‚ï¼‰
        amount_effect = -0.00001 * avg_purchase_amount
        
        # ã‚¢ãƒ—ãƒªåˆ©ç”¨é »åº¦åŠ¹æœï¼ˆãƒ‡ã‚¸ã‚¿ãƒ«è¦ªå’Œæ€§ï¼‰
        app_effect = 0.05 * np.tanh(app_usage - 1)
        
        # äº¤äº’ä½œç”¨åŠ¹æœï¼ˆå¹´é½¢Ã—æ€§åˆ¥ï¼‰
        interaction_effect = 0.08 * gender * np.exp(-(age - 25)**2 / 200)
        
        true_cate = (base_effect + age_effect + gender_effect + 
                    freq_effect + amount_effect + app_effect + interaction_effect)
        
        return true_cate
    
    def generate_propensity_score(self, df):
        """
        å‚¾å‘ã‚¹ã‚³ã‚¢ï¼ˆå‡¦ç½®ç¢ºç‡ï¼‰ã®ç”Ÿæˆ
        ç¾å®Ÿçš„ãªé¸æŠãƒã‚¤ã‚¢ã‚¹ã‚’å†ç¾
        """
        age = df['age'].values
        gender = df['gender'].values
        purchase_count = df['purchase_count'].values
        app_usage = df['app_usage'].values
        region = df['region'].values
        
        # å‚¾å‘ã‚¹ã‚³ã‚¢ã®ãƒ­ã‚¸ãƒƒãƒˆ
        logit_ps = (
            -0.5 +  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆç´„38%ã®é…ä¿¡ç¢ºç‡ï¼‰
            0.02 * (age - 40) +  # å¹´é½¢åŠ¹æœ
            0.3 * gender +  # å¥³æ€§ã«ã‚ˆã‚Šé…ä¿¡ã•ã‚Œã‚„ã™ã„
            0.1 * np.log(1 + purchase_count) +  # è³¼è²·å®Ÿç¸¾
            0.2 * app_usage +  # ã‚¢ãƒ—ãƒªåˆ©ç”¨è€…
            0.1 * (region == 0)  # é–¢æ±åœå„ªå…ˆ
        )
        
        # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å¤‰æ›
        propensity_score = 1 / (1 + np.exp(-logit_ps))
        
        # å…±é€šã‚µãƒãƒ¼ãƒˆã‚’ä¿è¨¼ï¼ˆ0.05 < ps < 0.95ï¼‰
        propensity_score = np.clip(propensity_score, 0.05, 0.95)
        
        return propensity_score
    
    def generate_outcome(self, df, treatment, true_cate):
        """
        ã‚¢ã‚¦ãƒˆã‚«ãƒ ï¼ˆå£²ä¸Šå¢—åŠ ç‡ï¼‰ã®ç”Ÿæˆ
        """
        age = df['age'].values
        gender = df['gender'].values
        avg_purchase_amount = df['avg_purchase_amount'].values
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å£²ä¸Šï¼ˆå‡¦ç½®ãªã—ã®å ´åˆï¼‰
        baseline = (
            0.1 +  # åŸºæœ¬æˆé•·ç‡10%
            0.005 * (age - 40) +  # å¹´é½¢åŠ¹æœ
            0.08 * gender +  # æ€§åˆ¥åŠ¹æœ
            0.00001 * avg_purchase_amount +  # å˜ä¾¡åŠ¹æœ
            np.random.normal(0, 0.15, len(df))  # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º
        )
        
        # å‡¦ç½®åŠ¹æœã‚’åŠ ç®—
        outcome = baseline + treatment * true_cate
        
        return outcome
    
    def generate_complete_data(self):
        """
        å®Œå…¨ãªCATEã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ
        """
        print("ğŸ”„ CATEåˆ†æç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        
        # é¡§å®¢ç‰¹å¾´é‡ç”Ÿæˆ
        df = self.generate_customer_features()
        
        # çœŸã®CATEã‚’è¨ˆç®—
        true_cate = self.true_cate_function(df)
        df['true_cate'] = true_cate
        
        # å‚¾å‘ã‚¹ã‚³ã‚¢è¨ˆç®—
        propensity_score = self.generate_propensity_score(df)
        df['true_propensity'] = propensity_score
        
        # å‡¦ç½®å‰²ã‚Šå½“ã¦ï¼ˆå‚¾å‘ã‚¹ã‚³ã‚¢ã«åŸºã¥ãï¼‰
        treatment = np.random.binomial(1, propensity_score)
        df['treatment'] = treatment
        
        # ã‚¢ã‚¦ãƒˆã‚«ãƒ ç”Ÿæˆ
        outcome = self.generate_outcome(df, treatment, true_cate)
        df['outcome'] = outcome
        
        # ç‰¹å¾´é‡ã®æ¨™æº–åŒ–ï¼ˆä¸€éƒ¨ï¼‰
        scaler = StandardScaler()
        df['age_scaled'] = scaler.fit_transform(df[['age']])
        df['purchase_count_scaled'] = scaler.fit_transform(df[['purchase_count']])
        
        print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(df)} samples")
        print(f"   å‡¦ç½®ç¾¤: {treatment.sum()} ({treatment.mean():.1%})")
        print(f"   çµ±åˆ¶ç¾¤: {(1-treatment).sum()} ({(1-treatment).mean():.1%})")
        print(f"   çœŸã®å¹³å‡åŠ¹æœ(ATE): {true_cate.mean():.4f}")
        print(f"   CATEåˆ†æ•£: {true_cate.std():.4f}")
        
        return df
    
    def create_train_test_split(self, df, test_size=0.3):
        """
        è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
        """
        n_test = int(len(df) * test_size)
        indices = np.random.permutation(len(df))
        
        train_df = df.iloc[indices[n_test:]].copy()
        test_df = df.iloc[indices[:n_test]].copy()
        
        return train_df, test_df

def generate_sample_data():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼šã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®å®Ÿè¡Œ
    """
    generator = CATESampleDataGenerator(n_samples=10000, random_state=42)
    df = generator.generate_complete_data()
    
    # åŸºæœ¬çµ±è¨ˆã®è¡¨ç¤º
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
    print(f"å¹´é½¢: {df['age'].mean():.1f} Â± {df['age'].std():.1f}")
    print(f"å¥³æ€§æ¯”ç‡: {df['gender'].mean():.1%}")
    print(f"å¹³å‡è³¼è²·å›æ•°: {df['purchase_count'].mean():.1f}")
    print(f"å¹³å‡è³¼è²·å˜ä¾¡: Â¥{df['avg_purchase_amount'].mean():,.0f}")
    
    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    train_df, test_df = generator.create_train_test_split(df)
    
    print(f"\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_df)} samples")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_df)} samples")
    
    return train_df, test_df, generator

# å®Ÿè¡Œä¾‹
if __name__ == "__main__":
    train_data, test_data, data_generator = generate_sample_data()
    
    # ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
    train_data.to_csv('sample_train_data.csv', index=False)
    test_data.to_csv('sample_test_data.csv', index=False)
    
    print("\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
    print("   - sample_train_data.csv")
    print("   - sample_test_data.csv")
