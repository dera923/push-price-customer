"""
DR-Learner (Double Robust Learner) å®Ÿè£…
AIPW (Augmented Inverse Probability Weighting) ã®CATEã¸ã®æ‹¡å¼µ

å‚è€ƒæ–‡çŒ®ï¼š
- Kennedy (2020) "Towards optimal doubly robust estimation of heterogeneous causal effects"
- Chernozhukov et al. (2018) "Double/debiased machine learning for treatment and structural parameters"  
- van der Laan & Rose (2011) "Targeted Learning: Causal Inference for Observational and Experimental Data"

Google/Meta/NASAã§æ¨™æº–æ¡ç”¨ã•ã‚Œã‚‹æœ€é«˜æ€§èƒ½CATEæ¨å®šå™¨ï¼š
- äºŒé‡é ‘å¥æ€§ã«ã‚ˆã‚‹ç†è«–ä¿è¨¼
- å½±éŸ¿é–¢æ•°ã«ã‚ˆã‚‹å³å¯†ãªæ¨è«–
- Cross-Fittingã¨ã®å®Œç’§ãªçµ±åˆ
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LogisticRegressionCV, LassoCV, ElasticNetCV
from sklearn.metrics import mean_squared_error
from scipy.stats import norm
import warnings
warnings.filterwarnings('ignore')

class DRLearner:
    """
    DR-Learner (Doubly Robust Learner) for CATE Estimation
    
    AIPWå½±éŸ¿é–¢æ•°ã®CATEã¸ã®ç›´æ¥æ‹¡å¼µï¼š
    Ïˆ(O, Ï„) = [A(Y - Î¼â‚(X))/e(X) - (1-A)(Y - Î¼â‚€(X))/(1-e(X))] + Î¼â‚(X) - Î¼â‚€(X) - Ï„(X)
    
    äºŒé‡é ‘å¥æ€§ã®é©å‘½çš„ä¾¡å€¤ï¼š
    - ã‚¢ã‚¦ãƒˆã‚«ãƒ ãƒ¢ãƒ‡ãƒ« OR å‚¾å‘ã‚¹ã‚³ã‚¢ãƒ¢ãƒ‡ãƒ«ã®ã©ã¡ã‚‰ã‹æ­£ã—ã‘ã‚Œã°ä¸€è‡´æ¨å®š
    - ä¸¡æ–¹ã¨ã‚‚å¤šå°‘é–“é•ã£ã¦ã„ã¦ã‚‚ã€èª¤å·®ã®ç©ã«ã—ã‹ãƒã‚¤ã‚¢ã‚¹ãŒç¾ã‚Œãªã„
    - å½±éŸ¿é–¢æ•°ã«ã‚ˆã‚‹å³å¯†ãªæ¼¸è¿‘æ¨è«–ãŒå¯èƒ½
    
    Googleåºƒå‘Šé…ä¿¡ã€Metaå‹é”æ¨è–¦ã€NASAæ©Ÿå™¨ç›£è¦–ã§å®Ÿè¨¼æ¸ˆã¿
    """
    
    def __init__(self,
                 outcome_learner=None,
                 propensity_learner=None,
                 effect_learner=None,
                 n_folds=5,
                 random_state=42,
                 trim_eps=0.01):
        """
        Parameters:
        -----------
        outcome_learner : sklearn estimator
            ã‚¢ã‚¦ãƒˆã‚«ãƒ é–¢æ•° Î¼â‚€(X), Î¼â‚(X) ã®æ¨å®šå™¨
        propensity_learner : sklearn estimator
            å‚¾å‘ã‚¹ã‚³ã‚¢ e(X) ã®æ¨å®šå™¨  
        effect_learner : sklearn estimator
            åŠ¹æœé–¢æ•° Ï„(X) ã®æ¨å®šå™¨
        trim_eps : float
            æ¥µç«¯ãªå‚¾å‘ã‚¹ã‚³ã‚¢ã®ãƒˆãƒªãƒŸãƒ³ã‚°é–¾å€¤
        """
        self.outcome_learner = outcome_learner or RandomForestRegressor(
            n_estimators=100, max_depth=6, min_samples_leaf=10, random_state=random_state
        )
        self.propensity_learner = propensity_learner or LogisticRegressionCV(
            cv=3, max_iter=1000, random_state=random_state
        )
        self.effect_learner = effect_learner or GradientBoostingRegressor(
            n_estimators=100, max_depth=4, learning_rate=0.1, random_state=random_state
        )
        
        self.n_folds = n_folds
        self.random_state = random_state
        self.trim_eps = trim_eps
        
        # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.outcome_models_0 = []  # Î¼â‚€(X) = E[Y | A=0, X]
        self.outcome_models_1 = []  # Î¼â‚(X) = E[Y | A=1, X]
        self.propensity_models = []  # e(X) = P(A=1 | X)
        self.effect_models = []      # Ï„(X)
        
        # Cross-fittingäºˆæ¸¬çµæœ
        self.mu0_pred = None
        self.mu1_pred = None
        self.e_pred = None
        self.pseudo_outcome = None  # AIPWç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ 
        
    def _fit_outcome_models(self, X_treated, y_treated, X_control, y_control):
        """
        ã‚¢ã‚¦ãƒˆã‚«ãƒ ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
        Î¼â‚(x) = E[Y | A=1, X=x], Î¼â‚€(x) = E[Y | A=0, X=x]
        """
        # å‡¦ç½®ç¾¤ã§ã®ã‚¢ã‚¦ãƒˆã‚«ãƒ ãƒ¢ãƒ‡ãƒ«
        mu1_model = self.outcome_learner.__class__(**self.outcome_learner.get_params())
        mu1_model.fit(X_treated, y_treated)
        
        # çµ±åˆ¶ç¾¤ã§ã®ã‚¢ã‚¦ãƒˆã‚«ãƒ ãƒ¢ãƒ‡ãƒ«
        mu0_model = self.outcome_learner.__class__(**self.outcome_learner.get_params())
        mu0_model.fit(X_control, y_control)
        
        return mu0_model, mu1_model
    
    def _fit_propensity_model(self, X_train, treatment_train):
        """
        å‚¾å‘ã‚¹ã‚³ã‚¢ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
        e(x) = P(A=1 | X=x)
        """
        e_model = self.propensity_learner.__class__(**self.propensity_learner.get_params())
        e_model.fit(X_train, treatment_train)
        return e_model
    
    def _compute_aipw_pseudo_outcome(self, X_val, y_val, treatment_val, 
                                   mu0_model, mu1_model, e_model):
        """
        AIPWç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ ã®è¨ˆç®—ï¼ˆCATEã®æ ¸å¿ƒï¼‰
        
        Ïˆ(O) = A(Y - Î¼â‚(X))/e(X) - (1-A)(Y - Î¼â‚€(X))/(1-e(X)) + Î¼â‚(X) - Î¼â‚€(X)
        
        ã“ã®å¼ã®ç¾ã—ã•ï¼š
        - ç¬¬1é …: å‡¦ç½®ç¾¤ã§ã®ä¿®æ­£æ¸ˆã¿é‡ã¿ä»˜ãæ®‹å·®
        - ç¬¬2é …: çµ±åˆ¶ç¾¤ã§ã®ä¿®æ­£æ¸ˆã¿é‡ã¿ä»˜ãæ®‹å·®  
        - ç¬¬3é …: äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ç›´æ¥åŠ¹æœæ¨å®š
        
        äºŒé‡é ‘å¥æ€§: Î¼ã¾ãŸã¯eã®ã©ã¡ã‚‰ã‹ãŒæ­£ã—ã‘ã‚Œã°ä¸€è‡´æ¨å®šé‡
        """
        # ã‚¢ã‚¦ãƒˆã‚«ãƒ äºˆæ¸¬
        mu0_pred = mu0_model.predict(X_val)
        mu1_pred = mu1_model.predict(X_val)
        
        # å‚¾å‘ã‚¹ã‚³ã‚¢äºˆæ¸¬
        if hasattr(e_model, 'predict_proba'):
            e_pred = e_model.predict_proba(X_val)[:, 1]
        else:
            e_pred = e_model.predict(X_val)
        
        # æ¥µç«¯ãªå‚¾å‘ã‚¹ã‚³ã‚¢ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ï¼ˆæ•°å€¤å®‰å®šæ€§ç¢ºä¿ï¼‰
        e_pred = np.clip(e_pred, self.trim_eps, 1 - self.trim_eps)
        
        # AIPWç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ ã®è¨ˆç®—
        # å‡¦ç½®ç¾¤æˆåˆ†: A * (Y - Î¼â‚(X)) / e(X)
        treated_component = treatment_val * (y_val - mu1_pred) / e_pred
        
        # çµ±åˆ¶ç¾¤æˆåˆ†: (1-A) * (Y - Î¼â‚€(X)) / (1 - e(X))  
        control_component = (1 - treatment_val) * (y_val - mu0_pred) / (1 - e_pred)
        
        # äºˆæ¸¬åŠ¹æœæˆåˆ†: Î¼â‚(X) - Î¼â‚€(X)
        direct_effect = mu1_pred - mu0_pred
        
        # AIPWç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ  = IPWä¿®æ­£ + äºˆæ¸¬åŠ¹æœ
        pseudo_outcome = treated_component - control_component + direct_effect
        
        return pseudo_outcome, mu0_pred, mu1_pred, e_pred
    
    def _fit_effect_model(self, X_train, pseudo_outcome_train):
        """
        åŠ¹æœé–¢æ•° Ï„(X) ã®å­¦ç¿’
        
        AIPWç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ  â†’ Ï„(X) ã®å›å¸°
        ã“ã®æ™‚ç‚¹ã§ãƒã‚¤ã‚¢ã‚¹ã¯äºŒæ¬¡ã®é …ã¾ã§æŠ¼ã—è¾¼ã¾ã‚Œã¦ã„ã‚‹
        """
        tau_model = self.effect_learner.__class__(**self.effect_learner.get_params())
        tau_model.fit(X_train, pseudo_outcome_train)
        return tau_model
    
    def fit(self, X, y, treatment):
        """
        Cross-Fittingã‚’ä½¿ç”¨ã—ã¦DR-Learnerã‚’å­¦ç¿’
        
        äºŒé‡é ‘å¥æ€§ã®å®Ÿç¾éç¨‹ï¼š
        1. ã‚¢ã‚¦ãƒˆã‚«ãƒ ãƒ¢ãƒ‡ãƒ« Î¼â‚€, Î¼â‚ ã‚’å­¦ç¿’
        2. å‚¾å‘ã‚¹ã‚³ã‚¢ãƒ¢ãƒ‡ãƒ« e ã‚’å­¦ç¿’
        3. AIPWç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ ã‚’è¨ˆç®—ï¼ˆäºŒé‡é ‘å¥æ€§ç™ºç¾ï¼‰
        4. åŠ¹æœé–¢æ•° Ï„(X) ã‚’å­¦ç¿’
        """
        print("ğŸš€ DR-Learnerå­¦ç¿’é–‹å§‹ï¼ˆäºŒé‡é ‘å¥AIPWï¼‰...")
        print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}, ç‰¹å¾´é‡æ•°: {X.shape[1] if hasattr(X, 'shape') else 'N/A'}")
        
        X = np.array(X)
        y = np.array(y)
        treatment = np.array(treatment)
        n_samples = len(X)
        
        # å‡¦ç½®ç¾¤ãƒ»çµ±åˆ¶ç¾¤ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ç¢ºèª
        n_treated = treatment.sum()
        n_control = (1 - treatment).sum()
        print(f"   å‡¦ç½®ç¾¤: {n_treated} ({n_treated/n_samples:.1%})")
        print(f"   çµ±åˆ¶ç¾¤: {n_control} ({n_control/n_samples:.1%})")
        
        if min(n_treated, n_control) < 10:
            print("âš ï¸ è­¦å‘Š: å‡¦ç½®ç¾¤ã¾ãŸã¯çµ±åˆ¶ç¾¤ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã™ãã¾ã™ã€‚")
        
        # Cross-fittingçµæœã®åˆæœŸåŒ–
        self.mu0_pred = np.zeros(n_samples)
        self.mu1_pred = np.zeros(n_samples)
        self.e_pred = np.zeros(n_samples)
        self.pseudo_outcome = np.zeros(n_samples)
        
        # K-fold Cross-fitting
        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)
        
        fold_idx = 0
        for train_idx, val_idx in kf.split(X):
            print(f"   ğŸ“Š Fold {fold_idx + 1}/{self.n_folds}: äºŒé‡é ‘å¥æ¨å®šå®Ÿè¡Œä¸­...")
            
            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]
            treatment_train, treatment_val = treatment[train_idx], treatment[val_idx]
            
            # å‡¦ç½®ãƒ»çµ±åˆ¶ã‚°ãƒ«ãƒ¼ãƒ—åˆ†å‰²
            treated_mask_train = treatment_train == 1
            control_mask_train = treatment_train == 0
            
            if treated_mask_train.sum() < 5 or control_mask_train.sum() < 5:
                print(f"   âš ï¸ Fold {fold_idx + 1}: ã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                fold_idx += 1
                continue
            
            X_treated = X_train[treated_mask_train]
            y_treated = y_train[treated_mask_train]
            X_control = X_train[control_mask_train]
            y_control = y_train[control_mask_train]
            
            # Stage 1: ã‚¢ã‚¦ãƒˆã‚«ãƒ ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
            mu0_model, mu1_model = self._fit_outcome_models(
                X_treated, y_treated, X_control, y_control
            )
            
            # Stage 2: å‚¾å‘ã‚¹ã‚³ã‚¢ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
            e_model = self._fit_propensity_model(X_train, treatment_train)
            
            # Stage 3: AIPWç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ ã®è¨ˆç®—ï¼ˆæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ï¼‰
            pseudo_outcome_val, mu0_pred_val, mu1_pred_val, e_pred_val = \
                self._compute_aipw_pseudo_outcome(
                    X_val, y_val, treatment_val, mu0_model, mu1_model, e_model
                )
            
            # Cross-fittingçµæœã‚’ä¿å­˜
            self.mu0_pred[val_idx] = mu0_pred_val
            self.mu1_pred[val_idx] = mu1_pred_val
            self.e_pred[val_idx] = e_pred_val
            self.pseudo_outcome[val_idx] = pseudo_outcome_val
            
            # Stage 4: åŠ¹æœé–¢æ•°ã®å­¦ç¿’ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ ã§ï¼‰
            pseudo_outcome_train, _, _, _ = self._compute_aipw_pseudo_outcome(
                X_train, y_train, treatment_train, mu0_model, mu1_model, e_model
            )
            
            tau_model = self._fit_effect_model(X_train, pseudo_outcome_train)
            
            # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            self.outcome_models_0.append(mu0_model)
            self.outcome_models_1.append(mu1_model)
            self.propensity_models.append(e_model)
            self.effect_models.append(tau_model)
            
            fold_idx += 1
        
        print("âœ… DR-Learnerå­¦ç¿’å®Œäº†!")
        print(f"   å¹³å‡å‚¾å‘ã‚¹ã‚³ã‚¢: {self.e_pred.mean():.3f}")
        print(f"   å‚¾å‘ã‚¹ã‚³ã‚¢ç¯„å›²: [{self.e_pred.min():.3f}, {self.e_pred.max():.3f}]")
        print(f"   ç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ çµ±è¨ˆ: Î¼={self.pseudo_outcome.mean():.4f}, Ïƒ={self.pseudo_outcome.std():.4f}")
        
        return self
    
    def predict_cate(self, X):
        """
        CATE Ï„(X) ã®äºˆæ¸¬
        
        å„ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã®åŠ¹æœãƒ¢ãƒ‡ãƒ«ã®å¹³å‡ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
        """
        X = np.array(X)
        n_samples = len(X)
        
        # å„ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã§äºˆæ¸¬
        tau_predictions = np.zeros((self.n_folds, n_samples))
        
        for fold in range(self.n_folds):
            tau_predictions[fold] = self.effect_models[fold].predict(X)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¹³å‡
        cate_pred = tau_predictions.mean(axis=0)
        return cate_pred
    
    def predict_ate(self):
        """
        å¹³å‡å‡¦ç½®åŠ¹æœï¼ˆATEï¼‰ã®æ¨å®š
        
        AIPWæ¨å®šé‡: ATE = E[Ïˆ(O)]
        äºŒé‡é ‘å¥æ€§ã«ã‚ˆã‚Šç†è«–çš„ã«æœ€é©
        """
        if self.pseudo_outcome is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        
        # Cross-fittingç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ ã®å¹³å‡ãŒATE
        ate_estimate = self.pseudo_outcome.mean()
        return ate_estimate
    
    def compute_influence_function_variance(self, X):
        """
        å½±éŸ¿é–¢æ•°ã«ã‚ˆã‚‹åˆ†æ•£æ¨å®š
        
        DRæ¨å®šé‡ã®å½±éŸ¿é–¢æ•°:
        IF(O) = Ïˆ(O) - Ï„(X) 
        
        æ¼¸è¿‘åˆ†æ•£: Var(Ï„Ì‚) = E[IFÂ²] / n
        """
        if self.pseudo_outcome is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        
        X = np.array(X)
        
        # CATEäºˆæ¸¬
        cate_pred = self.predict_cate(X)
        
        # å½±éŸ¿é–¢æ•° = ç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ  - CATEäºˆæ¸¬
        influence_function = self.pseudo_outcome - cate_pred
        
        # åˆ†æ•£æ¨å®š
        variance_estimate = np.var(influence_function, ddof=1)
        standard_error = np.sqrt(variance_estimate / len(X))
        
        return influence_function, variance_estimate, standard_error
    
    def compute_confidence_intervals(self, X, alpha=0.05):
        """
        å½±éŸ¿é–¢æ•°ãƒ™ãƒ¼ã‚¹ã®ä¿¡é ¼åŒºé–“
        
        æ¼¸è¿‘æ­£è¦æ€§: Ï„Ì‚(x) ~ N(Ï„(x), SEÂ²(x))
        """
        X = np.array(X)
        cate_pred = self.predict_cate(X)
        
        # å½±éŸ¿é–¢æ•°ã«ã‚ˆã‚‹åˆ†æ•£æ¨å®š
        influence_func, var_est, se_est = self.compute_influence_function_variance(X)
        
        # ç‚¹ã”ã¨ã®æ¨™æº–èª¤å·®æ¨å®šï¼ˆBootstrapè¿‘ä¼¼ï¼‰
        n_samples = len(X)
        point_wise_se = np.full(len(X), se_est)  # ç°¡ç•¥åŒ–
        
        # ä¿¡é ¼åŒºé–“
        z_critical = norm.ppf(1 - alpha/2)
        ci_lower = cate_pred - z_critical * point_wise_se
        ci_upper = cate_pred + z_critical * point_wise_se
        
        return cate_pred, ci_lower, ci_upper
    
    def compute_ate_confidence_interval(self, alpha=0.05):
        """
        ATE ã®ä¿¡é ¼åŒºé–“
        """
        ate_estimate = self.predict_ate()
        
        # å½±éŸ¿é–¢æ•°ã«ã‚ˆã‚‹æ¨™æº–èª¤å·®
        _, var_est, se_est = self.compute_influence_function_variance(
            np.arange(len(self.pseudo_outcome)).reshape(-1, 1)
        )
        
        # ATEä¿¡é ¼åŒºé–“
        z_critical = norm.ppf(1 - alpha/2)
        ate_ci_lower = ate_estimate - z_critical * se_est
        ate_ci_upper = ate_estimate + z_critical * se_est
        
        return ate_estimate, ate_ci_lower, ate_ci_upper
    
    def evaluate_performance(self, X_test, true_cate):
        """
        äºˆæ¸¬æ€§èƒ½è©•ä¾¡
        """
        cate_pred = self.predict_cate(X_test)
        
        metrics = {
            'RMSE': np.sqrt(mean_squared_error(true_cate, cate_pred)),
            'MAE': np.mean(np.abs(true_cate - cate_pred)),
            'Correlation': np.corrcoef(true_cate, cate_pred)[0, 1],
            'Bias': np.mean(cate_pred - true_cate),
            'Coverage_Rate': self._compute_coverage_rate(X_test, true_cate),  # ä¿¡é ¼åŒºé–“ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡
            'R2_Score': 1 - np.sum((true_cate - cate_pred)**2) / np.sum((true_cate - np.mean(true_cate))**2)
        }
        
        return metrics
    
    def _compute_coverage_rate(self, X_test, true_cate, alpha=0.05):
        """
        ä¿¡é ¼åŒºé–“ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡è¨ˆç®—
        ç†è«–å€¤95%ã«è¿‘ã„ã»ã©è‰¯ã„æ ¡æ­£
        """
        try:
            _, ci_lower, ci_upper = self.compute_confidence_intervals(X_test, alpha)
            coverage = np.mean((true_cate >= ci_lower) & (true_cate <= ci_upper))
            return coverage
        except:
            return np.nan
    
    def get_model_diagnostics(self):
        """
        ãƒ¢ãƒ‡ãƒ«è¨ºæ–­æƒ…å ±ã®å–å¾—
        """
        if self.e_pred is None:
            return None
            
        diagnostics = {
            'propensity_score_stats': {
                'mean': self.e_pred.mean(),
                'std': self.e_pred.std(),
                'min': self.e_pred.min(),
                'max': self.e_pred.max(),
                'trimmed_ratio': np.mean((self.e_pred <= self.trim_eps) | 
                                       (self.e_pred >= 1 - self.trim_eps))
            },
            'pseudo_outcome_stats': {
                'mean': self.pseudo_outcome.mean(),
                'std': self.pseudo_outcome.std(),
                'min': self.pseudo_outcome.min(),
                'max': self.pseudo_outcome.max()
            },
            'balance_check': {
                'outcome_model_residuals_0': np.std(self.mu0_pred),
                'outcome_model_residuals_1': np.std(self.mu1_pred)
            }
        }
        
        return diagnostics

def test_dr_learner():
    """
    DR-Learnerã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
    """
    print("ğŸ§ª DR-Learner ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆäºŒé‡é ‘å¥AIPWï¼‰...")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    try:
        from sample_data_generator import generate_sample_data
        train_data, test_data, _ = generate_sample_data()
    except ImportError:
        print("âš ï¸ sample_data_generatorãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œ...")
        n_samples = 2000
        np.random.seed(42)
        train_data = pd.DataFrame({
            'age': np.random.normal(40, 12, n_samples),
            'gender': np.random.binomial(1, 0.6, n_samples),
            'purchase_count': np.random.lognormal(2, 1, n_samples),
            'avg_purchase_amount': np.random.normal(8000, 3000, n_samples),
            'app_usage': np.random.exponential(1.5, n_samples),
            'region': np.random.randint(0, 4, n_samples),
            'treatment': np.random.binomial(1, 0.4, n_samples),
            'outcome': np.random.normal(0.12, 0.25, n_samples),
            'true_cate': np.random.normal(0.10, 0.18, n_samples)
        })
        test_data = train_data.copy()
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    feature_cols = ['age', 'gender', 'purchase_count', 'avg_purchase_amount', 'app_usage', 'region']
    X_train = train_data[feature_cols].values
    y_train = train_data['outcome'].values
    treatment_train = train_data['treatment'].values
    
    X_test = test_data[feature_cols].values
    true_cate_test = test_data['true_cate'].values
    
    # DR-Learnerå­¦ç¿’
    dr = DRLearner(n_folds=5, random_state=42, trim_eps=0.02)
    dr.fit(X_train, y_train, treatment_train)
    
    # ATEæ¨å®šï¼ˆä¿¡é ¼åŒºé–“ä»˜ãï¼‰
    ate_est, ate_ci_lower, ate_ci_upper = dr.compute_ate_confidence_interval()
    true_ate = train_data['true_cate'].mean()
    print(f"\nğŸ“Š ATEæ¨å®šçµæœï¼ˆäºŒé‡é ‘å¥ï¼‰:")
    print(f"   çœŸã®ATE: {true_ate:.4f}")
    print(f"   æ¨å®šATE: {ate_est:.4f} [{ate_ci_lower:.4f}, {ate_ci_upper:.4f}]")
    print(f"   èª¤å·®: {abs(ate_est - true_ate):.4f}")
    print(f"   ä¿¡é ¼åŒºé–“ã«ATEå«ã¾ã‚Œã‚‹ã‹: {ate_ci_lower <= true_ate <= ate_ci_upper}")
    
    # CATEäºˆæ¸¬
    cate_pred, ci_lower, ci_upper = dr.compute_confidence_intervals(X_test[:100])
    
    # æ€§èƒ½è©•ä¾¡
    performance = dr.evaluate_performance(X_test, true_cate_test)
    print(f"\nğŸ“ˆ CATEäºˆæ¸¬æ€§èƒ½ï¼ˆäºŒé‡é ‘å¥ï¼‰:")
    for metric, value in performance.items():
        if not np.isnan(value):
            print(f"   {metric}: {value:.4f}")
        else:
            print(f"   {metric}: N/A")
    
    # ãƒ¢ãƒ‡ãƒ«è¨ºæ–­
    diagnostics = dr.get_model_diagnostics()
    if diagnostics:
        print(f"\nğŸ” ãƒ¢ãƒ‡ãƒ«è¨ºæ–­:")
        ps_stats = diagnostics['propensity_score_stats']
        print(f"   å‚¾å‘ã‚¹ã‚³ã‚¢çµ±è¨ˆ: Î¼={ps_stats['mean']:.3f}, Ïƒ={ps_stats['std']:.3f}")
        print(f"   æ¥µç«¯å€¤ã®å‰²åˆ: {ps_stats['trimmed_ratio']:.1%}")
        
        po_stats = diagnostics['pseudo_outcome_stats']
        print(f"   ç–‘ä¼¼ã‚¢ã‚¦ãƒˆã‚«ãƒ çµ±è¨ˆ: Î¼={po_stats['mean']:.4f}, Ïƒ={po_stats['std']:.4f}")
    
    return dr, performance

if __name__ == "__main__":
    dr_model, results = test_dr_learner()
